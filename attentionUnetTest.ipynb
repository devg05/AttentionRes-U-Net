{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 128, 28, 28]) torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 64, 56, 56]) torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 112, 112]) torch.Size([1, 64, 112, 112])\n",
      "torch.Size([1, 2, 112, 112])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import resnet18, vgg16, densenet121\n",
    "from torch.nn import ConvTranspose2d, Conv2d\n",
    "from torch.nn.functional import max_pool2d as maxpool2d\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "def attention(x, g):\n",
    "        x = Conv2d(x.size(1), x.size(1), kernel_size=1, stride=1, padding=0)(x)\n",
    "        g = Conv2d(g.size(1), x.size(1), kernel_size=1, stride=1, padding=0)(g)\n",
    "        concat=x+g\n",
    "        r=nn.ReLU(inplace=True)(concat)\n",
    "        rconv=Conv2d(r.size(1), 1, kernel_size=1, stride=1, padding=0)(r)\n",
    "        psi = torch.sigmoid(rconv)\n",
    "        weight=nn.ConvTranspose2d(1, 1, kernel_size=1, stride=1, padding=0)(psi)\n",
    "        weighted_x=x*weight\n",
    "        res=weighted_x+g\n",
    "        return res\n",
    "class UNetResNet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNetResNet18, self).__init__()\n",
    "        \n",
    "        # Load ResNet-18 backbone\n",
    "        resnet = resnet18(pretrained=True)\n",
    "        vgg= vgg16(pretrained=True)\n",
    "        densenet= densenet121(pretrained=True)\n",
    "        self.encoder1 = nn.Sequential(*list(resnet.children())[:-2])  # Remove the fully connected layer and avgpool\n",
    "        self.encoder2 = nn.Sequential(*list(vgg.children())[:-2])\n",
    "        self.encoder3 = nn.Sequential(*list(densenet.children())[:-2])\n",
    "        # Encoder layers\n",
    "        self.enc11 = nn.Sequential(*list(resnet.children())[:3])  # First conv + BN + ReLU + MaxPool\n",
    "        self.enc112 = nn.Sequential(*list(resnet.children())[3:4])\n",
    "        self.enc12 = resnet.layer1\n",
    "        self.enc13 = resnet.layer2\n",
    "        self.enc14 = resnet.layer3\n",
    "        self.enc15 = resnet.layer4\n",
    "        # self.enc21 = nn.Sequential(*list(vgg.children())[:3])\n",
    "        # self.enc22 = vgg.features[3:8]\n",
    "        # self.enc23 = vgg.features[8:15]\n",
    "        # self.enc24 = vgg.features[15:22]\n",
    "        # self.enc25 = vgg.features[22:30]\n",
    "        # self.enc31 = nn.Sequential(*list(densenet.children())[:3])\n",
    "        # self.enc32 = densenet.denseblock1\n",
    "        # self.enc33 = densenet.transition1\n",
    "        # self.enc34 = densenet.denseblock2\n",
    "        # self.enc35 = densenet.transition2\n",
    "        # self.enc36 = densenet.denseblock3\n",
    "        # self.enc37 = densenet.transition3\n",
    "        # self.enc38 = densenet.denseblock4\n",
    "        # self.enc39 = densenet.norm5     \n",
    "        \n",
    "        # Decoder layers\n",
    "        self.dec4 = self._decoder_block(512, 256)\n",
    "        self.dec3 = self._decoder_block(256, 128)\n",
    "        self.dec2 = self._decoder_block(128, 64)\n",
    "        self.dec1 = self._decoder_block(64, 64)\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
    "        \n",
    "    def _decoder_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc11(x)\n",
    "        enc = self.enc112(enc1)\n",
    "        enc2 = self.enc12(enc)\n",
    "        enc3 = self.enc13(enc2)\n",
    "        enc4 = self.enc14(enc3)\n",
    "        enc5 = self.enc15(enc4)\n",
    "        \n",
    "        # Encoder\n",
    "        # enc21 = self.enc21(x)\n",
    "        # enc22 = self.enc22(enc21)\n",
    "        # enc23 = self.enc23(enc22)\n",
    "        # enc24 = self.enc24(enc23)\n",
    "        # enc25 = self.enc25(enc24)\n",
    "        \n",
    "        # # Encoder\n",
    "        # enc31 = self.enc31(x)\n",
    "        # enc32 = self.enc32(enc31)\n",
    "        # enc33 = self.enc33(enc32)\n",
    "        # enc34 = self.enc34(enc33)\n",
    "        # enc35 = self.enc35(enc34)\n",
    "        # enc36 = self.enc36(enc35)\n",
    "        # enc37 = self.enc37(enc36)\n",
    "        # enc38 = self.enc38(enc37)\n",
    "        # enc39 = self.enc39(enc38)\n",
    "        # Concatenate encoder outputs\n",
    "        # encf1 = torch.cat((enc1, enc21), dim=1)\n",
    "        # encf2 = torch.cat((enc2, enc22), dim=1)\n",
    "        # encf3 = torch.cat((enc3, enc23), dim=1)\n",
    "        # encf4 = torch.cat((enc4, enc24), dim=1)\n",
    "        # encf5 = torch.cat((enc5, enc25), dim=1)\n",
    "        \n",
    "        \n",
    "        # Decoder\n",
    "        # skip_enc4=Conv2d(256, 512, kernel_size=3, stride=1, padding='same')(enc4)\n",
    "        # skip_enc4=maxpool2d(skip_enc4, kernel_size=2, stride=2)(skip_enc4)\n",
    "        # skip_enc3=Conv2d(128, 256, kernel_size=3, stride=1, padding='same')\n",
    "        # skip_enc3=maxpool2d(skip_enc3, kernel_size=2, stride=2)(skip_enc3)\n",
    "        # skip_enc2=Conv2d(64, 128, kernel_size=3, stride=1, padding='same')\n",
    "        # skip_enc2=maxpool2d(skip_enc2, kernel_size=2, stride=2)(skip_enc2)\n",
    "        # skip_enc1=Conv2d(64, 64, kernel_size=3, stride=1, padding='same')\n",
    "        # skip_enc1=maxpool2d(skip_enc1, kernel_size=2, stride=2)(skip_enc1)\n",
    "\n",
    "        # gate_enc4=Conv2d(512, 512, kernel_size=3, stride=1, padding='same')\n",
    "        # cat_enc4=skip_enc4+gate_enc4\n",
    "        # l=nn.ReLU(inplace=True)(cat_enc4)\n",
    "\n",
    "        print((self.dec4(enc5)).size(), enc4.size())\n",
    "        dec4 = attention(self.dec4(enc5), enc4)\n",
    "        print((self.dec3(dec4)).size(), enc3.size())\n",
    "        dec3 = attention(self.dec3(dec4), enc3)\n",
    "        print((self.dec2(dec3)).size(), enc2.size())\n",
    "        dec2 = attention(self.dec2(dec3), enc2)\n",
    "        print((self.dec1(dec2)).size(), enc1.size())\n",
    "        dec1 = attention(self.dec1(dec2), enc1)\n",
    "        \n",
    "        # Final output\n",
    "        out = self.final_conv(dec1)\n",
    "        return out\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    model = UNetResNet18(num_classes=2)\n",
    "    x = torch.randn(1, 3, 224, 224)  # Batch size of 1, 3 channels (RGB), 224x224 image\n",
    "    output = model.forward(x)\n",
    "    print(output.shape)  # Should be [1, num_classes, 224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
